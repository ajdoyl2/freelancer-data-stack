version: '3.8'

networks:
  data-stack:
    driver: bridge

services:
  # Postgres - Used by Airbyte and Metabase for metadata
  postgres:
    image: postgres:15
    container_name: data-stack-postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: data_stack
      POSTGRES_MULTIPLE_DATABASES: airbyte,metabase
    volumes:
      - ${HOME}/data-stack/volumes/postgres:/var/lib/postgresql/data
      - ./scripts/init-multiple-databases.sh:/docker-entrypoint-initdb.d/init-multiple-databases.sh
    ports:
      - "5432:5432"
    networks:
      - data-stack
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Airbyte - Data integration platform
  airbyte-bootloader:
    image: airbyte/bootloader:0.50.33
    container_name: airbyte-bootloader
    environment:
      - AIRBYTE_VERSION=0.50.33
      - DATABASE_HOST=postgres
      - DATABASE_PORT=5432
      - DATABASE_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - DATABASE_USER=postgres
      - DATABASE_DB=airbyte
    networks:
      - data-stack
    depends_on:
      postgres:
        condition: service_healthy

  airbyte-db:
    image: airbyte/db:0.50.33
    container_name: airbyte-db
    restart: unless-stopped
    environment:
      - DATABASE_HOST=postgres
      - DATABASE_PORT=5432
      - DATABASE_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - DATABASE_USER=postgres
      - DATABASE_DB=airbyte
    networks:
      - data-stack
    depends_on:
      postgres:
        condition: service_healthy

  airbyte-worker:
    image: airbyte/worker:0.50.33
    container_name: airbyte-worker
    restart: unless-stopped
    environment:
      - AIRBYTE_VERSION=0.50.33
      - AUTO_DETECT_SCHEMA=true
      - DATABASE_HOST=postgres
      - DATABASE_PORT=5432
      - DATABASE_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - DATABASE_USER=postgres
      - DATABASE_DB=airbyte
      - WORKSPACE_ROOT=/tmp/workspace
      - WORKSPACE_DOCKER_MOUNT=airbyte_workspace
      - LOCAL_ROOT=/tmp/airbyte_local
      - LOCAL_DOCKER_MOUNT=/tmp/airbyte_local
      - CONFIG_ROOT=/data
      - TRACKING_STRATEGY=logging
    volumes:
      - ${HOME}/data-stack/volumes/airbyte/workspace:/tmp/workspace
      - ${HOME}/data-stack/volumes/airbyte/local:/tmp/airbyte_local
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - data-stack
    depends_on:
      - airbyte-bootloader

  airbyte-server:
    image: airbyte/server:0.50.33
    container_name: airbyte-server
    restart: unless-stopped
    environment:
      - AIRBYTE_VERSION=0.50.33
      - DATABASE_HOST=postgres
      - DATABASE_PORT=5432
      - DATABASE_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - DATABASE_USER=postgres
      - DATABASE_DB=airbyte
      - WORKSPACE_ROOT=/tmp/workspace
      - CONFIG_ROOT=/data
      - TRACKING_STRATEGY=logging
    ports:
      - "8000:8001"
    volumes:
      - ${HOME}/data-stack/volumes/airbyte/workspace:/tmp/workspace
      - ${HOME}/data-stack/volumes/airbyte/data:/data
    networks:
      - data-stack
    depends_on:
      - airbyte-bootloader

  airbyte-webapp:
    image: airbyte/webapp:0.50.33
    container_name: airbyte-webapp
    restart: unless-stopped
    ports:
      - "8001:80"
    environment:
      - AIRBYTE_ROLE=webapp
      - AIRBYTE_VERSION=0.50.33
      - API_URL=/api/v1/
    networks:
      - data-stack
    depends_on:
      - airbyte-server

  # Dagster - Data orchestration (will be replaced with Airflow)
  dagster:
    image: dagster/dagster-celery-docker:1.5.7
    container_name: data-stack-dagster
    environment:
      DAGSTER_POSTGRES_USER: postgres
      DAGSTER_POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DAGSTER_POSTGRES_DB: dagster
      DAGSTER_POSTGRES_HOSTNAME: postgres
      DAGSTER_POSTGRES_PORT: 5432
    volumes:
      - ${HOME}/data-stack/volumes/dagster:/opt/dagster/dagster_home
      - ${HOME}/data-stack/volumes/dagster/code:/opt/dagster/app
    ports:
      - "3000:3000"
    networks:
      - data-stack
    depends_on:
      postgres:
        condition: service_healthy

  # Kafka & Zookeeper for DataHub
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: data-stack-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - ${HOME}/data-stack/volumes/zookeeper/data:/var/lib/zookeeper/data
      - ${HOME}/data-stack/volumes/zookeeper/logs:/var/lib/zookeeper/log
    networks:
      - data-stack

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: data-stack-kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    volumes:
      - ${HOME}/data-stack/volumes/kafka:/var/lib/kafka/data
    ports:
      - "9092:9092"
    networks:
      - data-stack

  # DataHub
  datahub-gms:
    image: acryldata/datahub-gms:v0.11.0
    container_name: datahub-gms
    hostname: datahub-gms
    environment:
      - ENTITY_REGISTRY_CONFIG_PATH=/datahub/datahub-gms/resources/entity-registry.yml
      - DATAHUB_SERVER_TYPE=gms
      - DATAHUB_TELEMETRY_ENABLED=false
      - METADATA_SERVICE_AUTH_ENABLED=false
      - KAFKA_BOOTSTRAP_SERVER=kafka:9092
      - KAFKA_SCHEMAREGISTRY_URL=http://schema-registry:8081
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
      - NEO4J_HOST=neo4j:7474
      - NEO4J_URI=bolt://neo4j
      - NEO4J_USERNAME=neo4j
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-datahub}
    volumes:
      - ${HOME}/data-stack/volumes/datahub/gms:/tmp
    ports:
      - "8080:8080"
    networks:
      - data-stack
    depends_on:
      - kafka
      - elasticsearch
      - neo4j

  datahub-frontend:
    image: acryldata/datahub-frontend-react:v0.11.0
    container_name: datahub-frontend
    environment:
      - DATAHUB_GMS_HOST=datahub-gms
      - DATAHUB_GMS_PORT=8080
      - DATAHUB_SECRET=${DATAHUB_SECRET:-YouMustChangeThisSecretKey}
      - DATAHUB_APP_VERSION=1.0
      - DATAHUB_PLAY_MEM_BUFFER_SIZE=10MB
    volumes:
      - ${HOME}/data-stack/volumes/datahub/frontend:/tmp
    ports:
      - "9002:9002"
    networks:
      - data-stack
    depends_on:
      - datahub-gms

  # Supporting services for DataHub
  elasticsearch:
    image: elasticsearch:7.17.9
    container_name: data-stack-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - ${HOME}/data-stack/volumes/elasticsearch:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - data-stack

  neo4j:
    image: neo4j:4.4.9
    container_name: data-stack-neo4j
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD:-datahub}
      - NEO4J_dbms_default__database=graph.db
      - NEO4J_dbms_allow__upgrade=true
    volumes:
      - ${HOME}/data-stack/volumes/neo4j:/data
    ports:
      - "7474:7474"
      - "7687:7687"
    networks:
      - data-stack

  schema-registry:
    image: confluentinc/cp-schema-registry:7.4.0
    container_name: data-stack-schema-registry
    depends_on:
      - kafka
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:9092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    ports:
      - "8081:8081"
    networks:
      - data-stack

  # Great Expectations with Jupyter
  great-expectations:
    image: greatexpectations/great_expectations:latest
    container_name: data-stack-great-expectations
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=${JUPYTER_TOKEN:-}
    volumes:
      - ${HOME}/data-stack/volumes/great-expectations:/home/jovyan/work
    ports:
      - "8888:8888"
      - "8501:8501"  # Streamlit port
    networks:
      - data-stack

  # Evidence.dev development server
  evidence:
    image: evidence-dev/evidence:latest
    container_name: data-stack-evidence
    environment:
      - NODE_ENV=development
    volumes:
      - ${HOME}/data-stack/volumes/evidence:/app
    ports:
      - "3001:3000"
    networks:
      - data-stack

  # Metabase
  metabase:
    image: metabase/metabase:v0.47.0
    container_name: data-stack-metabase
    environment:
      MB_DB_TYPE: postgres
      MB_DB_DBNAME: metabase
      MB_DB_PORT: 5432
      MB_DB_USER: postgres
      MB_DB_PASS: ${POSTGRES_PASSWORD:-postgres}
      MB_DB_HOST: postgres
    volumes:
      - ${HOME}/data-stack/volumes/metabase:/metabase-data
    ports:
      - "3002:3000"
    networks:
      - data-stack
    depends_on:
      postgres:
        condition: service_healthy

  # DuckDB HTTP server
  duckdb-http:
    image: alex-merced/duckdb-http:latest
    container_name: data-stack-duckdb
    environment:
      - DUCKDB_DATABASE=/data/main.db
    volumes:
      - ${HOME}/data-stack/volumes/duckdb:/data
    ports:
      - "8002:8080"
    networks:
      - data-stack

  # Traefik reverse proxy and dashboard
  traefik:
    image: traefik:v3.0
    container_name: data-stack-traefik
    command:
      - "--api.dashboard=true"
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"
    ports:
      - "80:80"
      - "443:443"
      - "8090:8080"  # Traefik dashboard
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ${HOME}/data-stack/volumes/traefik:/data
    networks:
      - data-stack
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.dashboard.rule=Host(`traefik.localhost`)"
      - "traefik.http.routers.dashboard.service=api@internal"

volumes:
  postgres_data:
  airbyte_workspace:
  airbyte_data:
  airbyte_local:
  dagster_home:
  kafka_data:
  zookeeper_data:
  elasticsearch_data:
  neo4j_data:
  great_expectations_data:
  evidence_data:
  metabase_data:
  duckdb_data:
  traefik_data:
